{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhzgo6bJF1y6KeLbvHatcp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yadavrishikesh/BayesNF/blob/main/Portland_DailyTraffic_DataAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "quzmgDkAfQgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "270e7e11-8e0f-4f86-febb-df4244e0e3bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.9/23.9 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install -q bayesnf cartopy contextily geopandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "import contextily as ctx\n",
        "import geopandas as gpd\n",
        "import jax\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import datetime\n",
        "from urllib.parse import urlparse\n",
        "from bayesnf.spatiotemporal import BayesianNeuralFieldMAP"
      ],
      "metadata": {
        "id": "-bVG0GJCfqOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_portland_model(train_url, test_url):\n",
        "    \"\"\"\n",
        "    Trains a Bayesian Neural Field MAP model on specified Portland train data and tests on test data.\n",
        "\n",
        "    Parameters:\n",
        "    - train_url (str): URL to the training dataset CSV file.\n",
        "    - test_url (str): URL to the test dataset CSV file.\n",
        "\n",
        "    Returns:\n",
        "    - predictions_df (DataFrame): DataFrame containing true values, predicted mean, and quantiles.\n",
        "    \"\"\"\n",
        "    # Determine base directory from train_url and create unique outputs directory\n",
        "    train_name = os.path.basename(urlparse(train_url).path).split('.')[0]\n",
        "    test_name = os.path.basename(urlparse(test_url).path).split('.')[0]\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_dir = os.path.join(os.getcwd(), 'outputs', f'{train_name}_{test_name}_{timestamp}')\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Download and load datasets\n",
        "    !wget -q {train_url} -O train_data.csv\n",
        "    !wget -q {test_url} -O test_data.csv\n",
        "    df_train = pd.read_csv('train_data.csv', index_col=0, parse_dates=['datetime'])\n",
        "    df_test = pd.read_csv('test_data.csv', index_col=0, parse_dates=['datetime'])\n",
        "\n",
        "    # Log-transform response in training data\n",
        "    df_train_log = df_train.copy()\n",
        "    df_train_log['response'] = np.log1p(df_train_log['response'])\n",
        "\n",
        "    # Define and train the Bayesian Neural Field model\n",
        "    model = BayesianNeuralFieldMAP(\n",
        "        width=512,\n",
        "        depth=2,\n",
        "        freq='D',\n",
        "        seasonality_periods=['W'],\n",
        "        num_seasonal_harmonics=[2],\n",
        "        feature_cols=['datetime', 'lat', 'lon', 'speed', 'occupancy'],\n",
        "        target_col='response',\n",
        "        observation_model='NORMAL',\n",
        "        timetype='index',\n",
        "        standardize=['lat', 'lon', 'speed', 'occupancy'],\n",
        "    )\n",
        "\n",
        "    model = model.fit(df_train_log,\n",
        "                      seed=jax.random.PRNGKey(0),\n",
        "                      ensemble_size=10,\n",
        "                      num_epochs=1000)\n",
        "\n",
        "    # Process test data\n",
        "    df_test_cleaned = df_test.dropna(subset=['response'])\n",
        "    df_test_cleaned_log = df_test_cleaned.copy()\n",
        "    df_test_cleaned_log['response'] = np.log1p(df_test_cleaned_log['response'])\n",
        "\n",
        "    # Make predictions\n",
        "    yhat, yhat_quantiles = model.predict(df_test_cleaned, quantiles=(0.025, 0.5, 0.975))\n",
        "\n",
        "    # Compile results into DataFrame\n",
        "    predictions_df = pd.DataFrame({\n",
        "        'datetime': df_test_cleaned.index,\n",
        "        'True_Values': df_test_cleaned['response'],\n",
        "        'Predicted_Mean': yhat_quantiles[1],\n",
        "        'Quantile_0.025': yhat_quantiles[0],\n",
        "        'Quantile_0.975': yhat_quantiles[2]\n",
        "    })\n",
        "\n",
        "    # Save output in the unique outputs directory\n",
        "    output_path = os.path.join(output_dir, 'predictions_output.csv')\n",
        "    predictions_df.to_csv(output_path, index=False)\n",
        "\n",
        "    return predictions_df"
      ],
      "metadata": {
        "id": "8f49qrxAfwjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spatial predictions\n",
        "train_data_url = 'https://raw.githubusercontent.com/yadavrishikesh/BayesNF/main/data/train_data_Portland_daily_pred-type_spatIntpl.csv'\n",
        "test_data_url = 'https://raw.githubusercontent.com/yadavrishikesh/BayesNF/main/data/test_data_Portland_daily_pred-type_spatIntpl.csv'\n",
        "predictions_df = run_portland_model(train_data_url, test_data_url)\n",
        "predictions_df.head()"
      ],
      "metadata": {
        "id": "Ch8IgJ3jfxuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forecasting\n",
        "train_data_url = 'https://raw.githubusercontent.com/yadavrishikesh/BayesNF/main/data/train_data_Portland_daily_pred-type_forecast.csv'\n",
        "test_data_url = 'https://raw.githubusercontent.com/yadavrishikesh/BayesNF/main/data/test_data_Portland_daily_pred-type_forecast.csv'\n",
        "predictions_df = run_portland_model(train_data_url, test_data_url)\n",
        "predictions_df.head()"
      ],
      "metadata": {
        "id": "JR43JnXEf0fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Space-time predictions\n",
        "train_data_url = 'https://raw.githubusercontent.com/yadavrishikesh/BayesNF/main/data/train_data_Portland_daily_pred-type_spaceTime.csv'\n",
        "test_data_url = 'https://raw.githubusercontent.com/yadavrishikesh/BayesNF/main/data/test_data_Portland_daily_pred-type_spaceTime.csv'\n",
        "predictions_df = run_portland_model(train_data_url, test_data_url)\n",
        "predictions_df.head()"
      ],
      "metadata": {
        "id": "1FwG3XuCf33W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access it from Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy the 'outputs' directory to Google Drive\n",
        "!cp -r /content/outputs /content/drive/MyDrive/BayesNF/outputs_Portland_daily\n"
      ],
      "metadata": {
        "id": "j6AvZwlxf7An"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}